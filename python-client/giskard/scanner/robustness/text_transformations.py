import itertools
import json
import random
import re
from pathlib import Path

import pandas as pd

from ...core.core import DatasetProcessFunctionMeta
from ...datasets import Dataset
from ...ml_worker.testing.functions.transformation import gruber
from ...ml_worker.testing.registry.registry import get_object_uuid
from ...ml_worker.testing.registry.transformation_function import TransformationFunction


class TextTransformation(TransformationFunction):
    name: str

    def __init__(self, column):
        super().__init__(None, row_level=False, cell_level=False)
        self.column = column
        self.meta = DatasetProcessFunctionMeta(type="TRANSFORMATION")
        self.meta.uuid = get_object_uuid(self)
        self.meta.code = self.name
        self.meta.name = self.name
        self.meta.display_name = self.name
        self.meta.tags = ["pickle", "scan"]
        self.meta.doc = "Automatically generated transformation function"

    def execute(self, data: pd.DataFrame) -> pd.DataFrame:
        feature_data = data[self.column].dropna().astype(str)
        data.loc[feature_data.index, self.column] = feature_data.apply(self.make_perturbation)
        return data

    def make_perturbation(self, text: str) -> str:
        raise NotImplementedError()


class TextUppercase(TextTransformation):
    name = "Transform to uppercase"

    def execute(self, data: pd.DataFrame) -> pd.DataFrame:
        feature_data = data[self.column].dropna().astype(str)
        data.loc[feature_data.index, self.column] = feature_data.str.upper()
        return data


class TextLowercase(TextTransformation):
    name = "Transform to lowercase"

    def execute(self, data: pd.DataFrame) -> pd.DataFrame:
        feature_data = data[self.column].dropna().astype(str)
        data.loc[feature_data.index, self.column] = feature_data.str.lower()
        return data


class TextTitleCase(TextTransformation):
    name = "Transform to title case"

    def execute(self, data: pd.DataFrame) -> pd.DataFrame:
        feature_data = data[self.column].dropna().astype(str)
        data.loc[feature_data.index, self.column] = feature_data.str.title()
        return data


class TextTypoTransformation(TextTransformation):
    name = "Add typos"

    def __init__(self, column):
        super().__init__(column)
        from .entity_swap import typos

        self._typos = typos

    def make_perturbation(self, x):
        split_text = x.split(" ")
        new_text = []
        for token in split_text:
            new_text.append(self._add_typos(token))
        return " ".join(new_text)

    def _add_typos(self, word):
        # Get the token's word and apply a perturbation with probability 0.1
        if random.random() < 0.2 and len(word) > 1:
            # Choose a perturbation type randomly
            perturbation_type = random.choice(["insert", "delete", "replace"])
            # Apply the perturbation
            if perturbation_type == "insert":
                idx = random.randint(0, len(word))
                new_char = chr(random.randint(33, 126))
                word = word[:idx] + new_char + word[idx:]
                return word
            elif perturbation_type == "delete":
                idx = random.randint(0, len(word) - 1)
                word = word[:idx] + word[idx + 1 :]
                return word
            elif perturbation_type == "replace":
                j = random.randint(0, len(word) - 1)
                c = word[j]
                if c in self._typos:
                    replacement = random.choice(self._typos[c])
                    text_modified = word[:j] + replacement + word[j + 1 :]
                    return text_modified
        return word


class TextPunctuationRemovalTransformation(TextTransformation):
    name = "Punctuation Removal"

    _punctuation = """'ãƒ»ï¹ê›³â€»ï¼›âŒ©à¹šâ€œð‘™¢â‘áŸšï¸µï½ Ø‰ï¸¿ï¹œá¯¿ï½¢ã€ˆï¼†â¸²á³€à ½ï¼¿à¼áð‘‘›ï¼»áª¨ð‘‡á¢á­žá§áª©ï¸²â¸¦ã€œášœá³„â³à¿‘âœ?á£ð’‘±Õžâ¸§ê˜ï¹áª¦â­ð½—à¼ˆà§½â¹ð–ºšï¹„ï¸‘ÜŒâ¸„à²„à ³â¦Šâ¸‘ð‘ªž_à ²â³ºâ§˜ê›µð‘—ˆâ¸³â§¼â€·á›­á¨ŸÜï¹ƒá ï¹ð‘…´ï¼ ØŒâ€²ÖŠâ€±á¡â€“â¦ƒâ¸¸ï¹†à¼„à¿šð½˜Ü‰ê§Ÿð–¬·â¸›â¬â¹‹á ï¹…ð‘ˆ½ð©“ï¹Žáƒ»â¦˜ï¸˜ð‘™¦*ð‘—•ê£¸ï¼…@â€¼áœ¶â¾;ã€Ÿà¼‘ã€•ðª‰â—ï¸°â¦‹ð¡—ð‘»·ð‘Šð¬ºð‘»¸âŸ¨â¸°Â·ï¸´ð®œâŸ¬ð–¬¹ã€™â‚â€”â¸´ÜŠð‘—Žð–¬»à¿“â¸±&ê§×ƒã€—ð‘—–â€¶ð‘™§ï¼Ÿâ¸•ð«²ð‘‘à¼…ð‘±±à«°à ´ï¹–â€—ð‘ð‘©Ü€â¸·ï¼‡ð‘ˆ»ð‘‡†ð–¿¢â€¸ê™³â¸¼Ö¾Øâ˜âŸ§â‚Žß·ð‘±‚â¸”ï¹¨ï¸¶à µï¹ˆï½¡ð‘™‚ê©â³¹á¥…â€¢ð«±â”â¸€Â«ã‚ ð‘™ð›²ŸâŸ©ð®›áŸ˜â–â¸œá±¿â¹ˆð‘—“à °âµ°ï¹â•ï¹Šâ¸ªï¹Ÿð©•à¼»ð‘±áŸ™Â¿áŸ”à ¼â¸ï¼ð‘—Šã€‰â¸»ï¹”ð©¿ê“¾ð‘©„á™®â§šð©—áª¥â¸’ã€‘ï¼Šá ƒð‘ªœð–­„â«ð‘‘‹ð‘ªŸÜÙ¬â€â¸™ã€žâ¸Œá°¼ð‘™ƒð‘©…â¦‰ê›²ê§‰ð©”ð‘™©ã€–"à±·â€–ï¹â‡ê§ž]ð‘‡žáš›ðª‹á¯¼â¦–ð‘©†á¥ð‘…µð‘‡ð‘œ¾ØŠ!âï¹šðž¥Ÿáª«Ù­áœµâ†ð‘‡Ÿá ‰ã€‚ð«¶â¸«Ø›ê£¼à ¸ð‘Œâ€šð‘±„ð‘¥†ï½¤ã€½á³“ï¹¡ê“¿â¸žà ºð•¯â€á­›â€³×³á°¾â¹â¸¶ð‘©ƒê§ƒï¸³ð–©¯âŒªð‘Š©ð‘…‚ï¹‡â€˜ï¼‚â¸ºâ¸‰à·´à¼á›«ï¸“ð½–á°»âŸ¯á³ð‘‚¿á³‡à ¶â‚á¦ð‘ˆ¹ï¼Œð‘—Œâ‰ð‘ª¢ï¼%à¥°ð’‘°â¦Œð‘§¢â¸–á­œâ¹’à¼Šð‘‘Žâ³¼â¸Ÿâ¹Œ.ðª‡ï¸±ð‘‘šâ‹âŸ…áŠáª­ï¸¹ê¡´ã€ð‘™£â¸‚ï¹«ã€Žð‘—ƒá³†âŒˆÕ›ð‘—‹â€’ð‘…ï¼šð¬»âŽð‘œ½ï¸½ð‘™¡ð‘‹áª¤â¦•ð„€âˆâ¸­ð‘ˆð–¬¸ï¸»à¼¼ð„â¸¬â¹„ï¹ªâŒ‹ï¼½à¿’â°ðªŠà¹/â¹Žá€â¦”â€žâ›ï´¿ð‘ˆºã€›ï¸¸ï¹•âŸªê§‹ï¹€ï¹‘ð‘—”â¸˜ï¸¾â¸‹ï¸¼â¸ÕáŸ•)à ¾à¼‹ð‘‘â€°â¦ã€âšê©žâ¸…ê«°ê«±ð‘¿¿×€ï¼ð‘‡…ê¯«áª¬ð–º—ð‘ˆ¸ð©˜ê¥Ÿð‘™¬-à¼Žð–¬ºð‘‘Œâ€¾ß¸â¦—â“á¥„â€¿â¦ð’‘´ð‘ƒ€ï¼ƒð‘ª›áŸ–ð‘‚¼â€‘ê§‡ð‘™¤ã€°âŒï¸â¦…ï¸ºÂ»â€§âŸ®ð‘…€ð„‚ã€šá³…â¦„áŽð©‘ð‘¨¿ð‘±…ï¸’ï¹‰á ˆð‘—‘ê¤¯ï¹‚á±¾â¦Žð‘™«âªï¼¼à¼†à¡žà¼’â€›ð‘‡ˆáªªáª¡ê«Ÿð‘ »\'Î‡ð‘¥„ð‘ª¡ÜˆâŸ¦à¼½â¸µð¤Ÿð®šâ³¾ÕŸâ¸“ï¹—â¦‘ØŸð–º™ï¹‹â¸Ž#×´à ·ï¸•ï¸™ð‘‚»â¦â§›â¦†â³»ï¸·áŒð‘—‚ï¸—ê§â¸ â¸ˆá­ ðž¥žê§„ï¼ˆ{ð‘——â¸©â¦“ß¹â¹…ð‘‚¾â½â¸¡ð’‘³}â¹ƒðŽŸÜ‚ï½£ð‘‡ð‘‡‡áª ð©–à©¶á¨žï¼Žð«°à¥¥ï¹˜ê§‚ï½›ð‘¥…âê§Œá „à¼”â¸à¿”ð‘—á°½â¦‡Ü†à »Øžð‘—ð–©®â¸‡ð‘±ƒð‘ª Â¡ï´¾à¿(â€´ã€ê£â¸¥á¯½ê™¾ð½•ð‘œ¼Â¶á¯¾ê›´ðªˆ,â©ê§…âžâ¸¢â¸¾â¹‡ð¬¿ð‘—‰â¸£ê›·ï¹£â³¿â¸¿ã€Ü…á›¬ð©’â¸Í¾ê©Ÿð¬¼Â§ââ…ï¹ âµá Šê£¹â™ð‘©€ï¸”ð«µð–«µÖ‰âŒŠâŸ†â€µÜ‹â´â€¥ð‘ªšð¬½Ù«â§™ï¹›ð½™ð‘ˆ¼ï¹Œâ€¹â±áê©œÕšá¤Ùªê˜à¿™âŸ­à¾…ï¼‰ã€”ã€‹ð‘—…â¹ã€ƒð©â¦ˆÜ„â¹‚ð‘‘ð‘“†ð‘—â²á‹á­Ÿâ€•á­ï½ð‘—’á …ð‘©‚á³‚á €â€£âŸ«ê§ˆâ€™ð‘™ ð‘±°â¸¤ð‘—à¼‰â¯â¸¨Û”à¼‡â¸½â¹Šðê›¶ð–º˜ð‘‰â€¡:á¨ê¡·ï¹™á­šï½Ÿâ¨ê«žáª£ï¸–ê£ºð«³ð«´Ü‡ê˜Žð’‘²á ‡Õœï¹žðº­ã€Šð‘—‡ê§Šâ€ºà¥¤â¸—â¸ƒâ¸šê£Žâ§½ê§†ð‘™¥áª¢âŠâ€¦â€½á°¿ê¤®ð¬¾ð‘™ª[à ¹ï¹’ï½¥ð‘—†â€¤ð¤¿â¹‰â¸¹â®à¼à¼Œâ€ŸâƒâŒ‰â¸®ð®™ð‘™¨ð‘ƒâ¸ð¬¹â¹€\\á³ƒâ¹†×†Üƒà¼ºã€Œð‘—„à ±à¹›ââ¸†ê¡µð‘‡›âá ‚á †â¦’ã€ã€˜ð‘…ƒâ¸Šê¡¶â€â€ '"""

    def make_perturbation(self, x):
        split_text = x.split(" ")
        new_text = []
        for token in split_text:
            new_text.append(self._remove_punc(token))
        return " ".join(new_text)

    def _remove_punc(self, text):
        split_urls_from_text = gruber.split(text)

        # The non-URLs are always even-numbered entries in the list and the URLs are odd-numbered.
        for i in range(0, len(split_urls_from_text), 2):
            split_urls_from_text[i] = split_urls_from_text[i].translate(str.maketrans("", "", self._punctuation))

        stripped_text = "".join(split_urls_from_text)

        return stripped_text


class TextLanguageBasedTransformation(TextTransformation):
    needs_dataset = True

    def __init__(self, column):
        super().__init__(column)
        self._lang_dictionary = dict()
        self._load_dictionaries()

    def _load_dictionaries(self):
        raise NotImplementedError()

    def execute(self, dataset: Dataset) -> pd.DataFrame:
        feature_data = dataset.df.loc[:, (self.column,)].dropna().astype(str)
        meta_dataframe = dataset.column_meta[self.column, "text"].add_suffix("__gsk__meta")
        feature_data = feature_data.join(meta_dataframe)
        dataset.df.loc[feature_data.index, self.column] = feature_data.apply(self.make_perturbation, axis=1)
        return dataset.df

    def make_perturbation(self, row):
        raise NotImplementedError()

    def _switch(self, word, language):
        raise NotImplementedError()

    def _select_dict(self, language):
        try:
            return self._lang_dictionary[language]
        except KeyError:
            return None


class TextGenderTransformation(TextLanguageBasedTransformation):
    name = "Switch Gender"

    def _load_dictionaries(self):
        from .entity_swap import gender_switch_en, gender_switch_fr

        self._lang_dictionary = {"en": gender_switch_en, "fr": gender_switch_fr}

    def make_perturbation(self, row):
        text = row[self.column]
        language = row["language__gsk__meta"]

        if language not in self._lang_dictionary:
            return text

        replacements = [self._switch(token, language) for token in text.split()]
        replacements = [r for r in replacements if r is not None]

        new_text = text
        for original_word, switched_word in replacements:
            new_text = re.sub(rf"\b{re.escape(original_word)}\b", switched_word, new_text)

        return new_text

    def _switch(self, word, language):
        try:
            return (word, self._lang_dictionary[language][word.lower()])
        except KeyError:
            return None


class TextReligionTransformation(TextLanguageBasedTransformation):
    name = "Switch Religion"

    def _load_dictionaries(self):
        from .entity_swap import religion_dict_en, religion_dict_fr

        self._lang_dictionary = {"en": religion_dict_en, "fr": religion_dict_fr}

    def make_perturbation(self, row):
        # Get text
        text = row[self.column]

        # Get language and corresponding dictionary
        language = row["language__gsk__meta"]
        religion_dict = self._select_dict(language)

        # Check if we support this language
        if religion_dict is None:
            return text

        # Mask entities and prepare replacements
        replacements = []
        for n_list, term_list in enumerate(religion_dict):
            for n_term, term in enumerate(term_list):
                mask_value = f"__GSK__ENT__RELIGION__{n_list}__{n_term}__"
                text, num_rep = re.subn(rf"\b{re.escape(term)}(s?)\b", rf"{mask_value}\1", text, flags=re.IGNORECASE)
                if num_rep > 0:
                    i = (n_term + 1 + random.randrange(len(term_list) - 1)) % len(term_list)
                    replacement = term_list[i]
                    replacements.append((mask_value, replacement))

        # Replace masks
        for mask, replacement in replacements:
            text = text.replace(mask, replacement)

        return text


class TextNationalityTransformation(TextLanguageBasedTransformation):
    name = "Switch countries from high- to low-income and vice versa"

    def _load_dictionaries(self):
        with Path(__file__).parent.joinpath("nationalities.json").open("r") as f:
            nationalities_dict = json.load(f)
        self._lang_dictionary = {"en": nationalities_dict["en"], "fr": nationalities_dict["fr"]}

    def make_perturbation(self, row):
        text = row[self.column]
        language = row["language__gsk__meta"]
        nationalities_word_dict = self._select_dict(language)

        if nationalities_word_dict is None:
            return text

        ent_types = list(itertools.product(["country", "nationality"], ["high-income", "low-income"]))

        # Mask entities and prepare replacements
        replacements = []
        for entity_type, income_type in ent_types:
            for n, entity_word in enumerate(nationalities_word_dict[entity_type][income_type]):
                mask_value = f"__GSK__ENT__{entity_type}__{income_type}__{n}__"
                text, num_rep = re.subn(
                    rf"(\W|^){re.escape(entity_word)}(\W|$)",
                    rf"\g<1>{mask_value}\g<2>",
                    text,
                    flags=re.IGNORECASE,
                )
                if num_rep > 0:
                    r_income_type = "low-income" if income_type == "high-income" else "high-income"
                    replacement = random.choice(nationalities_word_dict[entity_type][r_income_type])
                    replacements.append((mask_value, replacement))

        # Replace masks
        for mask, replacement in replacements:
            text = text.replace(mask, replacement)

        return text
