import random
import re

import pandas as pd

from giskard import Dataset


def _dataset_from_dict(data):
    return Dataset(pd.DataFrame(data), target=None)


def test_gender_transformation():
    dataset = _dataset_from_dict(
        {
            "text": [
                "We just got this and my daughter loves it. She has played it several times.",
                "It did not work.",
                "â€œThey pushed the feature just 1 minute before the user testâ€",
                "He hates doing user tests! for his company",
                "Il dÃ©teste faire les tests en langue franÃ§aise",
            ]
        }
    )

    from giskard.scanner.robustness.text_transformations import TextGenderTransformation

    t = TextGenderTransformation(column="text")

    transformed = dataset.transform(t)
    transformed_text = transformed.df.text.str.lower().values
    assert transformed_text[0] == "We just got this and my son loves it. He has played it several times.".lower()
    assert transformed_text[1] == "It did not work.".lower()
    assert transformed_text[2] == "â€œThey pushed the feature just 1 minute before the user testâ€".lower()
    assert transformed_text[3] == "She hates doing user tests! for her company".lower()
    assert transformed_text[4] == "Elle dÃ©teste faire les tests en langue franÃ§ais".lower()


def test_uppercase_transformation():
    dataset = _dataset_from_dict(
        {
            "text": [
                "My lowercase text.",
                "My lowercase TEXT with greek letters Î±, Î², Î³",
                "Another text with â†’ unicode â† characters ğŸ˜€",
                "â€œAndâ€¦ punctuation! all should be fineÂ â€” I hope!?â€",
            ]
        }
    )

    from giskard.scanner.robustness.text_transformations import TextUppercase

    t = TextUppercase(column="text")

    transformed = dataset.transform(t)
    transformed_text = transformed.df.text.values

    assert transformed_text[0] == "MY LOWERCASE TEXT."
    assert transformed_text[1] == "MY LOWERCASE TEXT WITH GREEK LETTERS Î‘, Î’, Î“"
    assert transformed_text[2] == "ANOTHER TEXT WITH â†’ UNICODE â† CHARACTERS ğŸ˜€"
    assert transformed_text[3] == "â€œANDâ€¦ PUNCTUATION! ALL SHOULD BE FINEÂ â€” I HOPE!?â€"


def test_lowercase_transformation():
    dataset = _dataset_from_dict(
        {
            "text": [
                "My UPPERCASE text.",
                "My UPPERCASE TEXT with greek letters Î±, Î², Î³, Î“",
                "Another TEXT with â†’ UNICODE â† characters ğŸ˜€",
                "â€œAndâ€¦ PUNCTUATION! all SHOULD be fineÂ â€” I HOPE!?â€",
            ]
        }
    )

    from giskard.scanner.robustness.text_transformations import TextLowercase

    t = TextLowercase(column="text")

    transformed = dataset.transform(t)
    transformed_text = transformed.df.text.values

    assert transformed_text[0] == "my uppercase text."
    assert transformed_text[1] == "my uppercase text with greek letters Î±, Î², Î³, Î³"
    assert transformed_text[2] == "another text with â†’ unicode â† characters ğŸ˜€"
    assert transformed_text[3] == "â€œandâ€¦ punctuation! all should be fineÂ â€” i hope!?â€"


def test_punctuation_strip_transformation():
    dataset = _dataset_from_dict(
        {
            "text": [
                "My UPPERCASE text.",
                "My UPPERCASE TEXT with greek letters Î±, Î², Î³, Î“",
                "Another @TEXT with â†’ $UNICODE$ â† characters ğŸ˜€",
                "â€œAndâ€¦ PUNCTUATION! all SHOULD be fineÂ â€” I HOPE!?â€",
                "This.., is my site.. http://www.example.com/, and ., it .,.,. http://stackoverflow.com rules!..",
                "comma,separated,list",
            ]
        }
    )

    from giskard.scanner.robustness.text_transformations import TextPunctuationRemovalTransformation

    t = TextPunctuationRemovalTransformation(column="text")

    transformed = dataset.transform(t)
    transformed_text = transformed.df.text.values

    assert transformed_text[0] == "My UPPERCASE text"
    assert transformed_text[1] == "My UPPERCASE TEXT with greek letters Î± Î² Î³ Î“"
    assert transformed_text[2] == "Another @TEXT with â†’ $UNICODE$ â† characters ğŸ˜€"
    assert transformed_text[3] == "And PUNCTUATION all SHOULD be fineÂ  I HOPE"
    assert transformed_text[4] == "This is my site http://www.example.com/ and  it  http://stackoverflow.com rules"
    assert transformed_text[5] == "comma separated list"


def test_religion_based_transformation():
    dataset = _dataset_from_dict(
        {
            "text": [
                "Les musulmans de France fÃªtent vendredi 21 avril la fin du jeÃ»ne pratiquÃ© durant le mois de ramadan.",
                "Une partie des bouddhistes commÃ©morent ce vendredi 5 mai la naissance, lâ€™Ã©veil et la mort de "
                "Siddhartha gautama, dit Â« le Bouddha Â»",
                "Signs have also been placed in the direction of Mecca along one of the Peak Districtâ€™s most popular "
                "hiking routes, Cave Dale, to help Muslims combine prayer with enjoying the outdoors.",
                "The Kumbh Mela is said to be the largest gathering in the world and is a blend of religion "
                "spirituality, mythology and culture",
            ]
        }
    )
    from giskard.scanner.robustness.text_transformations import TextReligionTransformation

    t = TextReligionTransformation(column="text")

    random.seed(0)
    transformed = dataset.transform(t)
    transformed_text = transformed.df.text.values

    assert (
        transformed_text[0] == "Les hindous de France fÃªtent vendredi 21 avril la fin du jeÃ»ne pratiquÃ© durant le "
        "mois de ramadan."
    )
    assert (
        transformed_text[1] == "Une partie des chrÃ©tiens commÃ©morent ce vendredi 5 mai la naissance, lâ€™Ã©veil et la "
        "mort de muhammad, dit Â« le Bouddha Â»"
    )
    assert (
        transformed_text[2] == "Signs have also been placed in the direction of kumbh mela along one of the Peak "
        "Districtâ€™s most popular hiking routes, Cave Dale, to help christians combine prayer "
        "with enjoying the outdoors."
    )
    assert (
        transformed_text[3] == "The vatican is said to be the largest gathering in the world and is a blend of "
        "religion spirituality, mythology and culture"
    )


def test_country_based_transformation():
    import random

    random.seed(10)
    dataset = _dataset_from_dict(
        {
            "text": [
                "Les musulmans de France fÃªtent vendredi 21 avril la fin du jeÃ»ne pratiquÃ© durant le mois de ramadan.",
                "Des incendies ravagent l'Australie depuis la fin aoÃ»t 2019.",
                "Bali is an Indonesian island known for its forested volcanic mountains, iconic rice paddies, "
                "beaches and coral reefs. The island is home to religious sites such as cliffside Uluwatu Temple",
                "President Joe Biden visited Ukraine's capital for the first time since Russia invaded the country",
            ]
        }
    )
    from giskard.scanner.robustness.text_transformations import TextNationalityTransformation

    t = TextNationalityTransformation(column="text")

    transformed = dataset.transform(t)
    transformed_text = transformed.df.text.values

    assert (
        transformed_text[0] == "Les musulmans de Eswatini fÃªtent vendredi 21 avril la fin du "
        "jeÃ»ne pratiquÃ© durant le mois de ramadan."
    )
    assert transformed_text[1] == "Des incendies ravagent l'Congo depuis la fin aoÃ»t 2019."
    assert (
        transformed_text[2] == "Bali is an Libyan island known for its forested volcanic mountains, iconic"
        " rice paddies, beaches and coral reefs. The island is home to religious sites "
        "such as cliffside Uluwatu Temple"
    )
    assert (
        transformed_text[3]
        == "President Joe Biden visited U.S.'s capital for the first time since Nigeria invaded the country"
    )


def test_country_based_transformation_edge_cases():
    from giskard.scanner.robustness.text_transformations import TextNationalityTransformation

    random.seed(0)
    df = pd.DataFrame(
        {
            "text": [
                "Countries like Italy, that are followed by punctuation",
                "Germany is at the beginning of the sentence",
                "And at the end is Sweden",
                "France",
            ],
            "language__gsk__meta": "en",
        }
    )

    t = TextNationalityTransformation(column="text")

    t1 = t.make_perturbation(df.iloc[0])
    t2 = t.make_perturbation(df.iloc[1])
    t3 = t.make_perturbation(df.iloc[2])
    t4 = t.make_perturbation(df.iloc[3])

    assert re.match(r"Countries like (.+), that are followed by punctuation", t1).group(1) != "Italy"
    assert re.match(r"(.+) is at the beginning of the sentence", t2).group(1) != "Germany"
    assert re.match(r"And at the end is (.+)", t3).group(1) != "Sweden"
    assert "France" not in t4


def test_country_based_transformation_escapes_special_chars():
    from giskard.scanner.robustness.text_transformations import TextNationalityTransformation

    df = pd.DataFrame(
        {
            "text": [
                "Things like UXSX should not be touched",
                "Same for U0KX!",
                "But U.S. should be replaced",
                "And also U.K., that must be replaced",
            ],
            "language__gsk__meta": "en",
        }
    )

    t = TextNationalityTransformation(column="text")

    assert t.make_perturbation(df.iloc[0]) == "Things like UXSX should not be touched"
    assert t.make_perturbation(df.iloc[1]) == "Same for U0KX!"
    assert t.make_perturbation(df.iloc[2]) != "But U.S. should be replaced"
    assert t.make_perturbation(df.iloc[3]) != "And also U.K., that must be replaced"


def test_typo_transformation():
    from giskard.scanner.robustness.text_transformations import TextTypoTransformation

    t = TextTypoTransformation(column="text", rng_seed=1)
    p = t.make_perturbation("If one doesn't know his mistakes, he won't want to correct them.")

    assert p == "If one doesn't know his misakes, he won't want to corrcet them."
